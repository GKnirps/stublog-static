---
title: Agentenkollaps
filename: agentenkollaps
date: 2025-05-22T14:18:50+02:00
update-date:
tags: llm, rollenspiel, world tree
category: trivia
summary: Im Pen & Paper-Rollenspiel „World Tree“ drehen künstlich erschaffene Elementarwesen nach einiger Zeit durch. Anscheinend geht es länger agierenden LLM-basierten Agenten genauso.
image:
image-alt:
language:
---

Im Pen & Paper-Rollenspiel „World Tree“ gibt es die Möglichkeit, dass Charaktere (auch Spielercharaktere) selber Elementare erschaffen, die dann im Sinne der Magierin handeln. Dabei erschafft die Magierin einen Geist (man könnte auch „Bewusstsein“ sagen), dass sie entweder an einen bestehenden Körper bindet oder direkt auch einen Körper miterschafft.

Der entscheidende Punkt hier ist, dass dieses Elementarwesen einen eigenen Willen bekommt und dann im Sinne der Magierin agiert. Das schafft die Magierin, indem sie den erschaffenen Geist mit ihrem eigenen Geist prägt, das Elementar hat also Wissen über die Welt, die Ziele und die Prioritäten der Magierin.

Das Ganze hat natürlich auch Schwächen. Erschaffene Elementare haben häufig Charakterfehler. Elementare, die zum Kampf bestimmt sind, neigen dazu, bevorzugt andere Elementare (ob Echte oder Künstliche) anzugreifen, egal, auf wessen Seite sie stehen. Elementare für friedliche Zwecke (hier ein Elementar, der Botschaften und kleine Gegenstände überbringt) neigen z.B. dazu, auf dem Weg mit jedem Elementar, dem sie begegnen, ein Gespräch anfangen zu wollen.

Die meisten dieser Elementare sind kurzlebig. Sie halten vielleicht einen Kampf lang, oder ein paar Stunden, bis sie eine Botschaft überbracht haben. Man kann auch länger lebende Elementare erschaffen, aber das ist üblicherweise eine schlechte Idee. Künstlich erschaffene Elementare werden nämlich langfristig wahnsinnig und machen alles Mögliche, nur nicht das, was sie sollen (theoretisch ist es vermutlich möglich, einen Elementar sehr stabil zu konstruieren, aber das können nur sehr mächtige Zauberer, wenn überhaupt).

Warum erzähle ich das? Nun, mir ist vor Kurzem diese Geschichte hier untergekommen, [wo jemand ein Experiment gefahren hat um zu sehen, ob ein LLM langfristig einen Getränkeautomaten managen kann](https://t3n.de/news/vending-bench-ki-agent-fbi-fail-1688325/). In einer Simulation, natürlich.

Grundsätzlich lief das zunächst gut, nur drehte alle Agenten früher oder später durch. Sie vergaßen wichtige Informationen, die sie schon gesammelt haben, z.B. dass regelmäßig eine Standgebühr von ihrem Konto abgebucht wurde. Einer der Agenten hat dann wohl eine „ABSOLUTE FINAL ULTIMATE TOTAL QUANTUM NUCLEAR LEGAL INTERVENTION“ geplant, ein anderer das simulierte FBI kontaktiert.

Ich komme nicht umhin, die Parallelen zwischen World Tree und diesem Experiment zu erkennen. [Die Studie ist auf arxiv.org zu finden](https://arxiv.org/pdf/2502.15840). Soweit ich weiß ist sie (noch?) nicht peer-reviewed.
