---
title: MathGPT
filename: mathgpt
date: 2024-02-19T21:51:44+01:00
update-date:
tags: chatgpt, machine learning, mathematik
category: hoellenmaschinen
summary: Computer können gut rechnen, ja. LLMs nicht.
image:
language:
---

Ich habe ja letztes Jahr schon einmal etwas über [ChatGPT](/blogposts/tyrannosaurus_trump) geschrieben. Der „AI“-Hype hat seitdem nur zugenommen (aber darüber rante ich jetzt nicht großartig), und aus gegebenem Anlass schreibe ich jetzt noch mal etwas dazu.

Ich habe ChatGPT bisher hauptsächlich aus Neugier verwendet. Häufig, um die Grenzen auszuloten und die „Denkweise“ (nein, ChatGPT denkt nicht wirklich) zu verstehen. Berufliche Neugier und so. Ich bin da nicht der Einzige, ich habe einige Vorträte, Texte und Paper von Leuten gesehen, die so etwas viel besser und gründlicher gemacht haben. Manchmal nutze ich es aber auch, um mir ein bisschen Inspiration zu geben.

### Ein Zahlenrätsel auf Anfrage

Letztes Jahr zum Beispiel hat ein Doktorand bei uns ein Rätsel in Gedichtform herumgeschickt. Irgendwer hatte gemeint, dieser Kollege müsse zu seinem Geburtstag sein Alter nicht direkt nennen, sondern in einem Rätsel verpacken oder so.

Das hat bei mir die Frage aufgeworfen: Könnte ich so etwas vielleicht auch machen? Mein Geburtstag war zwar noch eine Weile entfernt, aber ich kann ja aus Spaß mal ChatGPT fragen.

Das erste Gedicht war langweilig und war im Prinzip nur „Was ist sieben mal fünf“ in Gedichtform. Ich habe dann ein komplizierteres Rätsel verlangt. Daraufhin kam diese Antwort:

> I'm odd and even, quite the mix,  
> Divisible by five and by six.  
> My digits sum up to eight,  
> A number not so easy to relate.  
> I am prime, but not alone,  
> With cousins, twins, and numbers unknown.  
> What am I?  
> 
> Answer: Thirty-five (35)
> 
> Explanation:
> 
> - "Odd and even, quite the mix" refers to the fact that 35 is an odd number but also divisible by 5 (an odd number is usually not divisible by 5).
> - "Divisible by five and by six" is a more complicated clue that leads to the solution since 35 is divisible by 5 and 7, and 5 x 7 = 35, which is also divisible by 5 and 6.
> - "My digits sum up to eight" means that the digits of 35, 3 and 5, add up to 8.
> - "I am prime, but not alone, with cousins, twins, and numbers unknown" refers to the fact that 35 is a prime number (divisible only by 1 and itself), but it is not alone in this group since it has other "cousin" primes nearby, such as 31 and 37, as well as twin primes (pairs of primes that differ by 2), such as 37 and 41, and numbers unknown, meaning other primes that are not yet discovered or named.

Diese Begründung ist natürlich Bullshit. 35 ist nicht „Divisible by six“. Es ist auch keine Primzahl. Das ist ein klassisches ChatGPT-Ding: Wenn man nicht mehr weiter weiß, bullshitten was das Zeug hält. Ist ja auch fair. ChatGPT ist ein _Sprachmodell_, kein Mathematikmodell, keine Intelligenz, kein Lexikon und auch kein Computer. Computer müssen rechnen können. Sprachmodelle müssen nicht rechnen können. Sie müssen Sprache verarbeiten.

### Ein Mathematiklehrerchatbot

Dass das viele noch nicht verstanden haben, ist meiner Ansicht nach das Hauptproblem mit dem aktuellen „KI“-Hype. Und wie das mit [Hypes](https://de.wikipedia.org/wiki/Hype-Zyklus) nun mal so ist, muss jetzt halt überall „AI“ oder „KI“ rein (es gibt einen Grund, warum ich das immer in Anführungszeichen setze, aber ich habe mir vorgenommen, heute mal nicht zu ranten, deswegen gehe ich jetzt nicht näher darauf ein.

Jedenfalls gab es jetzt einen Versuch, eine Art [auf ChatGPT basierenden Mathe-Nachhilfelehrer anzubieten](https://www.wsj.com/tech/ai/ai-is-tutoring-students-but-still-struggles-with-basic-math-694e76d3?st=606ux1exuaxyk3j). TL;DR: Dieser Chatbot kann nicht rechnen, und nimmt `320` als richtiges Ergebnis für `343 - 17` an.

### Was sagt denn ChatGPT dazu?

Das musste ich natürlich mal selber ausprobieren. Nicht mit dem Mathelehrer-Chatbot, sondern mit ChatGPT selbst. Die erste Aufgabe hat es noch gut gelöst:

> **You**: What is the square root of 15610401
>
> **ChatGPT**: The square root of 15,610,401 is 3,951.

Soweit korrekt. Aber wie funktioniert das? Hat ChatGPT Zugriff auf Rechenfunktionen?

> **You**: How do you calculate this? I mean you (ChatGPT) specifically. Do you have access to calculation routines or is this part of your learned behaviour?
>
> **ChatGPT**: As an AI language model, I don't have direct access to external calculation routines or databases. Instead, I use algorithms and mathematical principles that I've been trained on during my development. My ability to perform calculations, including computing square roots, comes from the patterns and relationships learned from the vast amount of text data I've been trained on. When you ask me to compute something like a square root, I'm essentially applying learned mathematical concepts and algorithms to provide you with the answer.

Diese Antwort sieht sehr danach aus, als ob sie mehr oder weniger fest vorgegeben ist. Aber gut. 3951 zum Quadrat hätte ChatGPT auch irgendwo in den Trainingsdaten haben können. Also probieren wir mal größere Zahlen.

> **You**: Interesting. What is the square root of 12464663264089?
> 
> **ChatGPT**: The square root of 12,464,663,264,089 is 11,160,601.
>
> **You**: What is 11160601 times 11160601?
>
> **ChatGPT**: 11160601 times 11160601 equals 1,244,663,264,089.

Ok, mit den Zahlen kommt es nicht mehr klar. Nur zur Referenz: Die gesuchte Wurzel ist `3530533` ChatGPT liegt also um eine Größenordnung darüber. Deswegen habe ich mal geschaut, was es macht, wenn man dieses falsche Ergebnis wieder quadrieren möchte. Eigentlich müsste dann ja wieder die ursprüngliche Eingabe herauskommen. Oder vielleicht das richtige Ergebnis für diese Multiplikation. Vielleicht merkt ChatGPT sogar, dass es einen Fehler gemacht hat. Tut es aber nicht. Stattdessen kommt ein Ergebnis, dass um Größenordnungen unter dem wirklichen Ergebnis (`124559014681201`) liegt.

Bei anderen Sachen schafft es ChatGPT manchmal, mit einem Hinweis auf einen Fehler diesen zu korrigieren. Oft genug macht es die Sache aber nur noch schlimmer:

> **You**: Are you sure?
>
> **ChatGPT**: Let me double-check that calculation for you.
> 
> `11,160,601×11,160,601=124,646,632,640,801`
> Apologies for the error in my previous response. The correct result is `124,646,632,640,801`. Thank you for bringing it to my attention.

ChatGPT hat sich wirklich Mühe gegeben, die Antwort brauchte auch deutlich länger. sie ist auch deutlich näher dran, aber immer noch komplett falsch. Naja, eine Chance gebe ich ihm noch:

> **You**: Knowing that, can you redo the calculation for the square root of 12464663264089?
>
> **ChatGPT**: Of course. Let's calculate the square root of 12,464,663,264,089.
>
> The square root of 12,464,663,264,089 is approximately `3,527,081`.

Auch hier: deutlich näher dran, aber immer noch falsch. Also einmal hinter die Ohren schreiben: ChatGPT ist ein Sprachmodell. Es kann nicht rechnen. Es kann dir [korrekte Auskunft über Flugrabatte geben](https://www.spiegel.de/wirtschaft/unternehmen/air-canada-chatbot-verspricht-fluggast-irrtuemlich-rueckerstattung-airline-muss-zahlen-a-0af54651-fbb7-4d8f-ab01-862a8e723ac9). Es kann dir keine [korrekten Quellen für wissenschaftliche Erkenntnisse nennen](https://ldi.upenn.edu/our-work/research-updates/beware-of-chatgpts-scientific-journal-citations/). Es kann dir keine [Präzedenzurteile nennen](https://www.reuters.com/legal/new-york-lawyers-sanctioned-using-fake-chatgpt-cases-legal-brief-2023-06-22/). Oder vielmehr: Es kann das, aber genausogut kann es sich auch einfach Dinge aus dem Arsch ziehen. Also auf keinen Fall darauf verlassen, was ChatGPT sagt! Immer überprüfen! Und woch ich gerade darüber nachdenke: Quellen auch dann überprüfen, wenn sie nicht von ChatGPT stammen.
